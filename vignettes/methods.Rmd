---
title: "Monitorer vos données d'enquête avec vizsurvey"
subtitle: "Vignette 3 — Méthodologie et principes"
author: "Thomas Delclite - Statbel"
output:
  rmarkdown::html_vignette:
    toc: true
    toc_depth: 3
vignette: >
  %\VignetteIndexEntry{Explorer et contrôler vos données avec vizsurvey}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(vizsurvey)
```

# Introduction

Cette vignette présente les fondements méthodologiques et les calculs sous-jacents à l’application `{vizsurvey}`. Comme expliqué dans la première vignette, `{vizsurvey}` n’a pas pour objectif de réaliser des tests statistiques ou de produire des résultats interprétés : il s’agit avant tout d’un outil d’exploration et de diagnostic, positionné entre la collecte et l’analyse des données dans le cycle du GSBPM. Autrement dit, `{vizsurvey}` n’infère rien ; il organise la lecture et met en évidence les points qui méritent une attention particulière.

Les calculs réalisés dans `{vizsurvey}` reposent sur des mesures simples mais robustes, telles que les distances, les rangs, les écarts types ou les écarts relatifs entre distributions. Ces mesures servent de repères visuels pour identifier d’éventuelles incohérences : variations anormales d’une vague à l’autre, écarts entre enquêteur-rices, changements brusques de distribution ou hausses inattendues du taux de non-réponse. Elles ne visent pas à produire un verdict statistique, mais à guider la réflexion analytique.

L’ensemble des fonctions utilisées dans `{vizsurvey}` a été conçu pour être applicable à tout type de variable, qu’elle soit catégorielle (codes, modalités, réponses à choix) ou numérique (valeurs continues, durées, âges, revenus). L’objectif est de fournir un cadre de calcul générique, reproductible et robuste, permettant d’assurer la comparabilité des résultats entre enquêtes, années ou domaines. La priorité a toujours été donnée à la stabilité des indicateurs et à la simplicité des formules, afin de faciliter leur lecture et leur appropriation par les équipes de terrain comme par les analystes.

Ces choix méthodologiques ne sont pas figés : ils ont été progressivement affinés au sein de Statbel, sur base des premiers résultats produits par l'interface.\
Les retours d’expérience des responsables d’enquête, les échanges entre service, ainsi que plusieurs références issues de la littérature sur la qualité des enquêtes ont guidé l’évolution des fonctions. Ainsi, `{vizsurvey}` reflète une démarche collective et empirique, fondée sur la confrontation directe aux données.

La publication de ce package vise à partager ces choix. En rendant publiques les formules, les fonctions et la logique de calcul, nous souhaitons favoriser la transparence, encourager la réutilisation et stimuler les contributions d’autres équipes confrontées à des problématiques similaires. Notre ambition est de construire, avec d’autres instituts de statistique et organismes de sondage, une base commune d’outils et de pratiques pour le monitoring des enquêtes, en intégrant les retours des enquêteur-rices et des responsables d'enquête et des méthodologues.

# `classify_df()` : extraire les agrégats

# `prepa_stats()` : extraire les agrégats

`prepa_stats()` vous renvoie un data.frame compilant les statistiques calculées pendant la préparation. Vous pouvez l'utiliser pour alimenter des rapports ou construire vos propres visualisations.

```{r eval=FALSE}
stats <- prepa_stats(iris,
                     var_group = "Species")
head(stats)
```

# `heat_map_group()` : personnaliser la visualisation

Pour générer une heatmap hors Shiny :

```{r eval=FALSE}
library(dplyr)

data_group <- stats %>%
  dplyr::filter(variable == "satisfaction")

heat_map_group(
  data_group,
  group_var   = "vg",
  interviewer = "interviewer",
  value       = "mean",
  show_legend = TRUE
)
```

Vous pouvez ajuster la palette via l'argument `palette` et contrôler les titres à l'aide de `title` et `subtitle`.

### `score_isoforest()` : détecter les profils atypiques

```{r eval=FALSE}
library(dplyr)

donnees_num <- df %>% dplyr::select(where(is.numeric))
iso_scores  <- score_isoforest(donnees_num)

head(iso_scores)
```

`{vizsurvey}` se veut donc un espace de collaboration ouverte : un point de départ pour mutualiser les efforts, confronter les approches et améliorer collectivement la qualité des enquêtes, étape par étape.

Cette vignette détaille les principes de calcul utilisés dans {vizsurvey}. Comme expliqué dans la vignette 1 , aucun test statistique n’est exécuté dans cet outil : {vizsurvey} ne tire aucune conclusion automatique. Son rôle est d’organiser l’exploration et de guider l’analyse, non de la remplacer.

Les calculs mis en œuvre reposent sur des mesures de distance, des rangs et des écarts types, appliqués de manière homogène à différents types de variables (catégorielles ou numériques). Ces mesures permettent de détecter les anomalies, repérer les ruptures entre vagues d’enquête, ou encore évaluer la stabilité des distributions au fil du temps.

# Objectif : des fonctions génériques et robustes

L’objectif central du développement méthodologique de `{vizsurvey}` est de proposer des **fonctions génériques**, capables de s’appliquer à tout type de variable observée dans une enquête :

-   variables **catégorielles** (choix, modalités, codes, flags),

-   variables **numériques** (durées, revenus, âges, scores),

-   variables **de suivi** (dates, identifiants enquêteur·rices, etc.).

Ces fonctions ont été conçues pour être :

-   **robustes**, afin de résister à la présence d’anomalies ou de valeurs manquantes ;

-   **cohérentes**, afin de pouvoir comparer les résultats entre vagues d’enquête ;

-   **reproductibles**, grâce à une structure de code claire et des formules explicites.

# Conclusion

`{vizsurvey}` propose un cadre ouvert et évolutif pour le contrôle et la compréhension des données d’enquête.\
En diffusant les formules, les fonctions et les principes de calcul, nous espérons contribuer à un **écosystème méthodologique partagé**, fondé sur la **transparence**, la **collaboration**, et la **qualité statistique**.

## Allers-retours analytiques

Avant de lancer cette fonction, assurez-vous que les colonnes sélectionnées sont numériques, sans valeurs manquantes excessives. Standardisez ou filtrez les variables constantes pour éviter des avertissements.
